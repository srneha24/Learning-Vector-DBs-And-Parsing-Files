{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "import nltk\n",
    "import json\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from dotenv import load_dotenv\n",
    "from gensim.models import Word2Vec\n",
    "from openai import OpenAI\n",
    "from psycopg2 import connect\n",
    "from psycopg2.extras import RealDictCursor\n",
    "from pgvector.psycopg2 import register_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_TEXT = \"Who was Quentin Beck?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download NLTK data files\n",
    "\n",
    "nltk.download('punkt', download_dir='./nltk')\n",
    "nltk.download('stopwords', download_dir='./nltk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare variables\n",
    "\n",
    "sample_file_path = \"samples\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read files and create tokens\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "doc_tokens = list()\n",
    "doc_content = list()\n",
    "doc_files = list()\n",
    "for sample_file in os.listdir(\"./\" + sample_file_path):\n",
    "    with open(f\"./{sample_file_path}/{sample_file}\", 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "        doc_content.append(content)\n",
    "        tokens = word_tokenize(content)\n",
    "        doc_tokens.append([word.lower() for word in tokens if word not in stop_words])\n",
    "        doc_files.append(sample_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "\n",
    "model = Word2Vec(sentences=doc_tokens, min_count=1, window=5, workers=4, vector_size=384)\n",
    "print(model)\n",
    "model.train(doc_tokens, total_examples=len(doc_tokens), epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Word2Vec`\n",
    "\n",
    "**sentences:** The list of sentences split into words in lowercase.\n",
    "\n",
    "**min_count:** Which words to consider in accordance to the number of times they appear in the sentences. For example, if set to 1, that means all the words that occur once or more in all of the sentences will be used to create the embeddings. If set to 2, then all the words that occur twice or more will be created embeddings for.\n",
    "\n",
    "**window:** The maximum distance between the current and predicted word within a sentence. That is, how many words to the left and right of a given word are considered when training the model.\n",
    "\n",
    "**workers:** How many CPU cores will be used.\n",
    "\n",
    "**vector_size:** Dimension of the vectors. Set as 384 because that is the Chroma DB default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create document embeddings\n",
    "\n",
    "doc_embeddings = list()\n",
    "for doc_token in doc_tokens:\n",
    "    valid_tokens = [token for token in doc_token if token in model.wv]\n",
    "    if not valid_tokens:\n",
    "        vector = np.zeros(model.vector_size)\n",
    "    else:\n",
    "        vector = np.mean([model.wv[token] for token in valid_tokens], axis=0)\n",
    "    doc_embeddings.append([float(value) for value in vector])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_ORGANIZATION_ID = os.getenv('OPENAI_ORGANIZATION_ID')\n",
    "OPENAI_PROJECT_ID = os.getenv('OPENAI_PROJECT_ID')\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "DB_HOST = os.getenv('DB_HOST')\n",
    "DB_NAME = os.getenv('DB_NAME')\n",
    "DB_USERNAME = os.getenv('DB_USERNAME')\n",
    "DB_PASSWORD = os.getenv('DB_PASSWORD')\n",
    "DB_PORT = os.getenv('DB_PORT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Postgres client\n",
    "\n",
    "pg_config = {\n",
    "    'host': DB_HOST,\n",
    "    'database': DB_NAME,\n",
    "    'user': DB_USERNAME,\n",
    "    'password': DB_PASSWORD,\n",
    "    'port': DB_PORT\n",
    "}\n",
    "\n",
    "pg_client = connect(**pg_config)\n",
    "cursor = pg_client.cursor()\n",
    "register_vector(pg_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create database table\n",
    "\n",
    "create_table_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS embeddings (\n",
    "            id SERIAL PRIMARY KEY, \n",
    "            document VARCHAR(200),\n",
    "            content text,\n",
    "            embedding vector(384)\n",
    "            );\n",
    "            \"\"\"\n",
    "cursor.execute(create_table_query)\n",
    "pg_client.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate table\n",
    "\n",
    "for i in range(len(doc_content)):\n",
    "    temp = (doc_files[i], doc_content[i], doc_embeddings[i])\n",
    "    cursor.execute(\"INSERT into embeddings(document, content, embedding) VALUES (%s, %s, %s)\", temp)\n",
    "\n",
    "print(\"Insertion Complete\")\n",
    "pg_client.commit()\n",
    "cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed user query\n",
    "\n",
    "query_tokens = word_tokenize(QUERY_TEXT)\n",
    "query_tokens = [word.lower() for word in query_tokens if word not in stop_words]\n",
    "\n",
    "query_model = Word2Vec(sentences=query_tokens, min_count=1, window=5, workers=4, vector_size=384)\n",
    "print(query_model)\n",
    "query_model.train(query_tokens, total_examples=len(query_tokens), epochs=10)\n",
    "\n",
    "valid_tokens = [token for token in query_tokens if token in query_model.wv]\n",
    "if not valid_tokens:\n",
    "    query_embeddings = np.zeros(query_model.vector_size)\n",
    "else:\n",
    "    query_embeddings = np.mean([query_model.wv[token] for token in valid_tokens], axis=0)\n",
    "\n",
    "query_embeddings = list(map(float, query_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve content from DB\n",
    "\n",
    "with pg_client.cursor(cursor_factory=RealDictCursor) as cursor:\n",
    "    cursor.execute(\"SELECT content FROM embeddings ORDER BY embedding <=> %s::vector LIMIT 2\", (query_embeddings,))\n",
    "    resultant_contents = cursor.fetchall()\n",
    "    cursor.close()\n",
    "pg_client.close()\n",
    "\n",
    "print(resultant_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate OpenAI client\n",
    "\n",
    "openai = OpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    organization=OPENAI_ORGANIZATION_ID,\n",
    "    project=OPENAI_PROJECT_ID\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making OpenAI request\n",
    "\n",
    "tools = list()\n",
    "for resultant_content in resultant_contents:\n",
    "    temp = {\n",
    "      \"type\": \"function\",\n",
    "      \"function\": {\n",
    "        \"name\": \"information\",\n",
    "        \"description\": \"the chat information\",\n",
    "        \"parameters\": {\n",
    "          \"type\": \"object\",\n",
    "          \"properties\": {\n",
    "            \"text\": {\n",
    "              \"type\": \"string\",\n",
    "              \"description\": resultant_content.get('content'),\n",
    "            },\n",
    "          },\n",
    "          \"required\": [\"text\"],\n",
    "        },\n",
    "      }\n",
    "    }\n",
    "    tools.append(temp)\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are an assistant.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": QUERY_TEXT\n",
    "    }\n",
    "]\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    tools=tools,\n",
    "    tool_choice={\"type\": \"function\", \"function\": {\"name\": \"information\"}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieving OpenAI response\n",
    "\n",
    "result = response.choices[0].message.tool_calls[0].function.arguments\n",
    "result_json = json.loads(result)\n",
    "print(result_json.get('text'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
